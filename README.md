# やっていること

REST形式とRPC形式の通信の動作確認兼検証

具滝的にはgRPCサーバーの1リクエスト1レスポンス（Unary RPCs）とFastAPIサーバー環境を構築して、同じレスポンスを行わせる。

## 結果

500弱メガバイトの文字列のレスポンスを行わせたところ、gRPCのほうがおよそ2秒弱早かった


レスポンス秒数
| | gRPC | FastAPI |
|:-----------|-----------:|:------------:|
|	|	1.125675440 秒	|	2.794412374 秒	|
|	|	1.072984695 秒	|	2.807909012 秒	|
|	|	1.078088999 秒	|	2.782161713 秒	|
|	|	1.074341774 秒	|	2.788344383 秒	|
|	|	1.073608398 秒	|	2.781672001 秒	|
|	平均|	1.084939861 秒	|	2.790899897 秒	|

# 起動

>docker-compose build --no-cache

>docker-compose up -d

・gRPCサーバーに入る
>docker-compose exec python-grpc-server sh

・fastAPIサーバーに入る
>docker-compose exec python-fastapi-server sh

## テスト
・それぞれのサーバーで以下を実行する

>python test_request.py

それぞれのサーバーからのレスポンス内容は同じ。

それぞれのサーバーのレスポンス時間とレイテンシーの確認ができる

# 思ったこと
Protocol BuffersやOpenAPIを使って仕様を記述してソースコードの自動生成を行えるのは両者共通で便利。（今回OpenAPIは使ってませんが）

しかし今後は（要件等によりますが）gRPCを積極的に採用したいと思いました。理由としては以下
- 単純に速度が改善される
- HTTP/2がデフォルト
- gRPCの国内外の採用事例とメリデメを見たところ
  - メルカリやGMOなどの採用事例やPoCを読むのが一番納得できるのでおすすめ、、
